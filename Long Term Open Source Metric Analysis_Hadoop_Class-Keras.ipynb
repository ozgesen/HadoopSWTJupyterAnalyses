{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7338adff",
   "metadata": {},
   "source": [
    "# Long Term Open Source Metric Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623f327",
   "metadata": {},
   "source": [
    "# Hadoop Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e7896c0",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "Step1: Downloaded Hadoop versions from Hadoop Archive (https://hadoop.apache.org/release.html) as soruce from Hadoop Belowing specified the versionsCK metrics extracted using ck project (https://github.com/mauricioaniche/ck.git)\n",
    "\n",
    "2.9.2, 2.9.1, 2.9.0,2.8.5, 2.8.4, 2.8.3,2.8.2, 2.8.1,2.8.0,\n",
    "2.7.7,2.7.6,2.7.5,2.7.3,2.7.2,2.7.1,2.7.0,2.6.5, 2.6.4,2.6.3,\n",
    "2.6.2,2.6.1,2.6.0,2.5.2,2.5.1,2.5.0,2.4.1,2.4.0,2.3.0,3.3.0, \n",
    "3.3.1, 3.3.2, 3.3.3, 3.3.4, 3.3.5,3.3.6,3.2.0, 3.3.1, 3.2.2, 3.2.3, 3.2.4,3.1.0,3.1.1,3.1.2,3.1.3,3.1.4,3.0.0,3.0.1,3.0.2,3.0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de593aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop_versions = [\n",
    "         \"2.9.2\", \"2.9.1\", \"2.9.0\",\"2.8.5\", \"2.8.4\", \"2.8.3\",\"2.8.2\", \"2.8.1\",\"2.8.0\",\n",
    "        \"2.7.7\",\"2.7.6\",\"2.7.5\",\"2.7.3\",\"2.7.2\",\"2.7.1\",\"2.7.0\",\"2.6.5\", \"2.6.4\",\"2.6.3\"\n",
    "        ,\"2.6.2\",\"2.6.1\",\"2.6.0\",\"2.5.2\",\"2.5.1\",\"2.5.0\",\"2.4.1\",\"2.4.0\",\"2.3.0\"\n",
    "        ,\"3.3.0\", \"3.3.1\", \"3.3.2\", \"3.3.3\", \"3.3.4\", \"3.3.5\",\"3.3.6\"\n",
    "       ,\"3.2.0\", \"3.3.1\", \"3.2.2\", \"3.2.3\", \"3.2.4\"\n",
    "       ,\"3.1.0\",\"3.1.1\",\"3.1.2\",\"3.1.3\",\"3.1.4\"\n",
    "       ,\"3.0.0\",\"3.0.1\",\"3.0.2\",\"3.0.3\"\n",
    "    ]\n",
    "\n",
    "\n",
    "neededColumnsClass =['cbo','cboModified','fanin','fanout','wmc','dit','noc','lcom',\n",
    "                     'lcom*','tcc','lcc', 'loc'\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b36124f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hadoop_versions)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c8d8c98",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "Step2: All ck - version data joined in one dataset both class and method aspects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d76d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "classCkMetricsAllVersionsDfClass = pd.read_csv('DataSource/hadoop_AllCkMetricsAllVersionsClass.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52586d3d",
   "metadata": {},
   "source": [
    "Step3: Read bug, new feature and improvement dataset that collcected from Jira (https://issues.apache.org/). Colllect filtered related version issues and solved and has version information ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "506128dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoopBugsAllDf = pd.read_csv('DataSource/hadoop_bugs_all.csv')\n",
    "hadoopNewFeaturesAllDf = pd.read_csv('DataSource/hadoop_newFeature_all.csv')\n",
    "hadoopImprovementsAllDf = pd.read_csv('DataSource/hadoop_improvements_all.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c680c78c",
   "metadata": {},
   "source": [
    "Step4: Clean the Ck dataset. Some classes are just test classes or unit test so we need to clean data and filter test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33118ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedCkMetricsAllVersionsDf = (classCkMetricsAllVersionsDfClass\n",
    "    .loc[~classCkMetricsAllVersionsDfClass['class'].str.contains(\"Test\")]\n",
    "    .loc[~classCkMetricsAllVersionsDfClass['class'].str.contains(\"test\")]\n",
    "    .loc[~classCkMetricsAllVersionsDfClass['class'].str.contains(\"TEST\")]\n",
    "    .loc[~classCkMetricsAllVersionsDfClass['file'].str.contains(\"src/test/\")]\n",
    ") "
   ]
  },
  {
   "cell_type": "raw",
   "id": "def50e4f",
   "metadata": {},
   "source": [
    "Lets check the data sizes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c3f460b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrelenmiş Sınıf Sayısı: 445474\n",
      "Versionlanmış hata sayısı: 21640\n",
      "Versionlanmış yeni özellik sayısı: 3139\n",
      "Versionlanmış geliştirme sayısı: 258\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Version</th>\n",
       "      <th>file</th>\n",
       "      <th>class</th>\n",
       "      <th>type</th>\n",
       "      <th>cbo</th>\n",
       "      <th>cboModified</th>\n",
       "      <th>fanin</th>\n",
       "      <th>fanout</th>\n",
       "      <th>wmc</th>\n",
       "      <th>...</th>\n",
       "      <th>assignmentsQty</th>\n",
       "      <th>mathOperationsQty</th>\n",
       "      <th>variablesQty</th>\n",
       "      <th>maxNestedBlocksQty</th>\n",
       "      <th>anonymousClassesQty</th>\n",
       "      <th>innerClassesQty</th>\n",
       "      <th>lambdasQty</th>\n",
       "      <th>uniqueWordsQty</th>\n",
       "      <th>modifiers</th>\n",
       "      <th>logStatementsQty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.9.2</td>\n",
       "      <td>/Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...</td>\n",
       "      <td>org.apache.hadoop.mapreduce.v2.app.rm.RMHeartb...</td>\n",
       "      <td>interface</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.9.2</td>\n",
       "      <td>/Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...</td>\n",
       "      <td>org.apache.hadoop.yarn.server.federation.store...</td>\n",
       "      <td>class</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.9.2</td>\n",
       "      <td>/Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...</td>\n",
       "      <td>org.apache.hadoop.fs.FileSystem</td>\n",
       "      <td>class</td>\n",
       "      <td>63</td>\n",
       "      <td>190</td>\n",
       "      <td>127</td>\n",
       "      <td>63</td>\n",
       "      <td>278</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>47</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1040</td>\n",
       "      <td>1025</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.9.2</td>\n",
       "      <td>/Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...</td>\n",
       "      <td>org.apache.hadoop.hdfs.DFSUtil$ConfiguredNNAdd...</td>\n",
       "      <td>innerclass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.9.2</td>\n",
       "      <td>/Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...</td>\n",
       "      <td>org.apache.hadoop.mapreduce.lib.output.Sequenc...</td>\n",
       "      <td>innerclass</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Version                                               file  \\\n",
       "0           0   2.9.2  /Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...   \n",
       "3           3   2.9.2  /Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...   \n",
       "4           4   2.9.2  /Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...   \n",
       "5           5   2.9.2  /Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...   \n",
       "6           6   2.9.2  /Users/ayferuckan/Desktop/TezÇalışmam/HadoopMe...   \n",
       "\n",
       "                                               class        type  cbo  \\\n",
       "0  org.apache.hadoop.mapreduce.v2.app.rm.RMHeartb...   interface    0   \n",
       "3  org.apache.hadoop.yarn.server.federation.store...       class    3   \n",
       "4                    org.apache.hadoop.fs.FileSystem       class   63   \n",
       "5  org.apache.hadoop.hdfs.DFSUtil$ConfiguredNNAdd...  innerclass    0   \n",
       "6  org.apache.hadoop.mapreduce.lib.output.Sequenc...  innerclass    2   \n",
       "\n",
       "   cboModified  fanin  fanout  wmc  ...  assignmentsQty  mathOperationsQty  \\\n",
       "0            3      3       0    2  ...               0                  0   \n",
       "3            9      6       3    1  ...               1                  0   \n",
       "4          190    127      63  278  ...             116                 47   \n",
       "5            0      0       0    5  ...               3                  1   \n",
       "6            2      0       2    6  ...               3                  0   \n",
       "\n",
       "   variablesQty  maxNestedBlocksQty  anonymousClassesQty  innerClassesQty  \\\n",
       "0             0                   0                    0                0   \n",
       "3             1                   0                    0                0   \n",
       "4            94                   6                    6                5   \n",
       "5             3                   0                    0                0   \n",
       "6             1                   0                    0                0   \n",
       "\n",
       "   lambdasQty  uniqueWordsQty  modifiers  logStatementsQty  \n",
       "0           0              12          1                 0  \n",
       "3           0              29       1025                 0  \n",
       "4           0            1040       1025                18  \n",
       "5           0              22          9                 0  \n",
       "6           0              29          9                 0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Filtrelenmiş Sınıf Sayısı:\", cleanedCkMetricsAllVersionsDf.shape[0])\n",
    "print(\"Versionlanmış hata sayısı:\", hadoopBugsAllDf.shape[0])\n",
    "print(\"Versionlanmış yeni özellik sayısı:\", hadoopImprovementsAllDf.shape[0])\n",
    "print(\"Versionlanmış geliştirme sayısı:\", hadoopNewFeaturesAllDf.shape[0])\n",
    "cleanedCkMetricsAllVersionsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf905c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b40ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hadoopBugsGroupedDf = hadoopBugsAllDf.groupby(['AVersion']).count().reset_index()\n",
    "hadoopImprovementsGroupedDf= hadoopImprovementsAllDf.groupby(['Fix Version/s']).count().reset_index()\n",
    "hadoopNewFeaturesGroupedDf= hadoopNewFeaturesAllDf.groupby(['Fix Version/s']).count().reset_index()\n",
    "\n",
    "hadoopBugsGroupedDf = hadoopBugsGroupedDf.rename(columns = {'AVersion': 'Version','Issue key': 'Count'})[['Version','Count']]\n",
    "hadoopImprovementsGroupedDf = hadoopImprovementsGroupedDf.rename(columns = {'Fix Version/s': 'Version','Issue key': 'Count'})[['Version','Count']]\n",
    "hadoopNewFeaturesGroupedDf = hadoopNewFeaturesGroupedDf.rename(columns = {'Fix Version/s': 'Version','Issue key': 'Count'})[['Version','Count']]\n",
    "\n",
    "metricsAllVersionsDf = pd.merge(cleanedCkMetricsAllVersionsDf, hadoopBugsGroupedDf,on=\"Version\", how='inner')\n",
    "ckMetricsAllVersionsDf = metricsAllVersionsDf.dropna()\n",
    "ckMetricsAllVersionsDf.columns = ckMetricsAllVersionsDf.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c7e1d02f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBO</th>\n",
       "      <th>CBOMODIFIED</th>\n",
       "      <th>FANIN</th>\n",
       "      <th>FANOUT</th>\n",
       "      <th>WMC</th>\n",
       "      <th>DIT</th>\n",
       "      <th>NOC</th>\n",
       "      <th>LCOM</th>\n",
       "      <th>LCOM*</th>\n",
       "      <th>TCC</th>\n",
       "      <th>LCC</th>\n",
       "      <th>LOC</th>\n",
       "      <th>NUMERICVERSION</th>\n",
       "      <th>COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>292</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>190</td>\n",
       "      <td>127</td>\n",
       "      <td>63</td>\n",
       "      <td>278</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>14945</td>\n",
       "      <td>0.985463</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>1510</td>\n",
       "      <td>292</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>292</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>21</td>\n",
       "      <td>292</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>292</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CBO  CBOMODIFIED  FANIN  FANOUT  WMC  DIT  NOC   LCOM     LCOM*       TCC  \\\n",
       "0    0            3      3       0    2    1    0      1  0.000000  0.000000   \n",
       "2   63          190    127      63  278    3   15  14945  0.985463  0.002395   \n",
       "3    0            0      0       0    5    1    0      0  0.400000  0.500000   \n",
       "4    2            2      0       2    6    1    0      0  0.166667  0.666667   \n",
       "5    3            3      0       3    2    2    0      1  0.000000  0.000000   \n",
       "\n",
       "        LCC   LOC  NUMERICVERSION  COUNT  \n",
       "0  0.000000     4             292     34  \n",
       "2  0.004649  1510             292     34  \n",
       "3  1.000000    22             292     34  \n",
       "4  0.666667    21             292     34  \n",
       "5  0.000000     8             292     34  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vckMetricsAllVersionsDf = ckMetricsAllVersionsDf\n",
    "vckMetricsAllVersionsDf.loc[:, 'NUMERICVERSION']  = ckMetricsAllVersionsDf['VERSION'].apply(lambda x: int(''.join(x.split('.'))))\n",
    "\n",
    "selected_columns = ['CBO', 'CBOMODIFIED', 'FANIN', 'FANOUT', 'WMC', 'DIT', 'NOC', 'LCOM',\n",
    "       'LCOM*', 'TCC', 'LCC', 'LOC', 'NUMERICVERSION','COUNT' ]\n",
    "df = vckMetricsAllVersionsDf[selected_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96c36f6d",
   "metadata": {},
   "source": [
    "Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "39d9ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('COUNT', axis=1)  \n",
    "y = df['COUNT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "85c59c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254360, 13)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a3b6e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Normalization()         #(1)\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")  #(2)\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()                  #(3)\n",
    "output_layer = tf.keras.layers.Dense(1)                       #(4)\n",
    "\n",
    "\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9e259d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " normalization_4 (Normalization  (None, 13)          27          ['input_5[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 30)           420         ['normalization_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 30)           930         ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 43)           0           ['normalization_4[0][0]',        \n",
      "                                                                  'dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1)            44          ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,421\n",
      "Trainable params: 1,394\n",
      "Non-trainable params: 27\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "672c1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mse\", \n",
    "    optimizer=optimizer, \n",
    "    metrics=[\"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3ac2deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "normalization_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "827877a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6359/6359 [==============================] - 3s 419us/step - loss: 41288.7578 - root_mean_squared_error: 203.1964 - val_loss: 39499.0000 - val_root_mean_squared_error: 198.7436\n",
      "Epoch 2/20\n",
      "6359/6359 [==============================] - 3s 407us/step - loss: 39200.2812 - root_mean_squared_error: 197.9906 - val_loss: 36766.5742 - val_root_mean_squared_error: 191.7461\n",
      "Epoch 3/20\n",
      "6359/6359 [==============================] - 3s 407us/step - loss: 36185.8984 - root_mean_squared_error: 190.2259 - val_loss: 34395.8906 - val_root_mean_squared_error: 185.4613\n",
      "Epoch 4/20\n",
      "6359/6359 [==============================] - 3s 407us/step - loss: 34755.9609 - root_mean_squared_error: 186.4295 - val_loss: 33034.7070 - val_root_mean_squared_error: 181.7545\n",
      "Epoch 5/20\n",
      "6359/6359 [==============================] - 3s 406us/step - loss: 32352.6562 - root_mean_squared_error: 179.8684 - val_loss: 29367.8750 - val_root_mean_squared_error: 171.3706\n",
      "Epoch 6/20\n",
      "6359/6359 [==============================] - 3s 408us/step - loss: 26804.3457 - root_mean_squared_error: 163.7203 - val_loss: 23058.9668 - val_root_mean_squared_error: 151.8518\n",
      "Epoch 7/20\n",
      "6359/6359 [==============================] - 3s 412us/step - loss: 21048.1133 - root_mean_squared_error: 145.0797 - val_loss: 17869.9121 - val_root_mean_squared_error: 133.6784\n",
      "Epoch 8/20\n",
      "6359/6359 [==============================] - 3s 422us/step - loss: 16393.0371 - root_mean_squared_error: 128.0353 - val_loss: 14545.7627 - val_root_mean_squared_error: 120.6058\n",
      "Epoch 9/20\n",
      "6359/6359 [==============================] - 3s 409us/step - loss: 14402.1777 - root_mean_squared_error: 120.0091 - val_loss: 13872.0859 - val_root_mean_squared_error: 117.7798\n",
      "Epoch 10/20\n",
      "6359/6359 [==============================] - 3s 411us/step - loss: 14160.8604 - root_mean_squared_error: 118.9994 - val_loss: 13641.3086 - val_root_mean_squared_error: 116.7960\n",
      "Epoch 11/20\n",
      "6359/6359 [==============================] - 3s 410us/step - loss: 14074.5020 - root_mean_squared_error: 118.6360 - val_loss: 13611.1855 - val_root_mean_squared_error: 116.6670\n",
      "Epoch 12/20\n",
      "6359/6359 [==============================] - 3s 410us/step - loss: 13949.3164 - root_mean_squared_error: 118.1072 - val_loss: 13673.1748 - val_root_mean_squared_error: 116.9324\n",
      "Epoch 13/20\n",
      "6359/6359 [==============================] - 3s 413us/step - loss: 13913.3320 - root_mean_squared_error: 117.9548 - val_loss: 13498.5674 - val_root_mean_squared_error: 116.1833\n",
      "Epoch 14/20\n",
      "6359/6359 [==============================] - 3s 410us/step - loss: 13837.0703 - root_mean_squared_error: 117.6311 - val_loss: 13399.9209 - val_root_mean_squared_error: 115.7580\n",
      "Epoch 15/20\n",
      "6359/6359 [==============================] - 3s 422us/step - loss: 13786.6143 - root_mean_squared_error: 117.4164 - val_loss: 13441.4717 - val_root_mean_squared_error: 115.9374\n",
      "Epoch 16/20\n",
      "6359/6359 [==============================] - 3s 413us/step - loss: 13753.8496 - root_mean_squared_error: 117.2768 - val_loss: 13435.0977 - val_root_mean_squared_error: 115.9099\n",
      "Epoch 17/20\n",
      "6359/6359 [==============================] - 3s 412us/step - loss: 13721.6973 - root_mean_squared_error: 117.1396 - val_loss: 13530.6973 - val_root_mean_squared_error: 116.3215\n",
      "Epoch 18/20\n",
      "6359/6359 [==============================] - 3s 412us/step - loss: 13675.4180 - root_mean_squared_error: 116.9419 - val_loss: 13165.4990 - val_root_mean_squared_error: 114.7410\n",
      "Epoch 19/20\n",
      "6359/6359 [==============================] - 3s 408us/step - loss: 13661.2578 - root_mean_squared_error: 116.8814 - val_loss: 13136.1338 - val_root_mean_squared_error: 114.6130\n",
      "Epoch 20/20\n",
      "6359/6359 [==============================] - 3s 411us/step - loss: 13556.2324 - root_mean_squared_error: 116.4312 - val_loss: 13433.5029 - val_root_mean_squared_error: 115.9030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7e135bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650/2650 [==============================] - 1s 273us/step - loss: 40578.9961 - root_mean_squared_error: 201.4423\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54fa91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
